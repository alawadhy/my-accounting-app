import pandas as pd
import requests
import hashlib
import streamlit as st
import io
import json
from datetime import datetime
from supabase import create_client 

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø¢Ù…Ù†Ø© (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Secrets) ---
# Ø³ÙŠØ¨Ø­Ø« Streamlit Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù†ØµØ© ÙˆÙ„ÙŠØ³ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
try:
    URL = st.secrets["supabase"]["SUPABASE_URL"]
    KEY = st.secrets["supabase"]["SUPABASE_KEY"]
except KeyError:
    st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø§ØªØµØ§Ù„. ØªØ£ÙƒØ¯ Ù…Ù† Ø¶Ø¨Ø· Secrets ÙÙŠ Streamlit Cloud.")
    st.stop()

# Ø§Ù„Ù‡ÙŠØ¯Ø±Ø² Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ Requests
HEADERS = {
    "apikey": KEY,
    "Authorization": f"Bearer {KEY}",
    "Content-Type": "application/json",
    "Prefer": "return=representation"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ supabase Ø§Ù„Ø±Ø³Ù…ÙŠ
# Ù†Ø¶Ù…Ù† Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠÙ†ØªÙ‡ÙŠ Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø³Ø­Ø§Ø¨
supabase_url = URL.replace("/rest/v1", "") if "/rest/v1" in URL else URL
supabase = create_client(supabase_url, KEY)

def check_system_health():
    try:
        # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        acc_check = supabase.table("accounts").select("*", count="exact").limit(1).execute()
        jou_check = supabase.table("journal").select("*", count="exact").limit(1).execute()
        
        info = {
            "accounts_columns": ["id", "acc_name", "category", "current_balance"], # Ù…Ø«Ø§Ù„
            "journal_columns": ["id", "jv_date", "acc_name", "total_amount"] # Ù…Ø«Ø§Ù„
        }
        return True, info
    except Exception as e:
        return False, str(e)

# --- 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
def verify_user(username, password):
    try:
        # ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„Ù…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§ Ù…Ø¹ Ø§Ù„Ù…Ø®Ø²Ù†
        input_hash = hashlib.sha256(password.encode()).hexdigest()
        
        response = supabase.table("users").select("*").eq("username", username.lower()).execute()
        
        if response.data:
            user = response.data[0]
            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù‡Ø§Ø´ Ø§Ù„Ù…Ø´ÙØ± ÙÙ‚Ø·
            if user['password'] == input_hash:
                return True, {
                    "username": user['username'],
                    "full_name": user.get('full_name', user['username']),
                    "role": user['role'],
                    "can_delete": user.get('can_delete_entry', 0),
                    "can_reports": user.get('can_view_reports', 0),
                    "can_settings": user.get('can_edit_settings', 0),
                    "can_users": user.get('can_manage_users', 0)
                }
        return False, None
    except Exception as e:
        return False, None

# --- 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† (Ø¬Ù„Ø¨ØŒ Ø¥Ø¶Ø§ÙØ©ØŒ Ø­Ø°Ù) ---

def get_all_users():
    """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© Supabase"""
    try:
        response = supabase.table("users").select("*").execute()
        if response.data:
            return pd.DataFrame(response.data)
        return pd.DataFrame()
    except Exception as e:
        print(f"Error fetching users: {e}")
        return pd.DataFrame()

def add_new_user(username, full_name, password, role, can_delete, can_reports, can_settings, can_users):
    try:
        # ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ÙÙˆØ±Ø§Ù‹ Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ (Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ…)
        hashed_pw = hashlib.sha256(password.encode()).hexdigest()
        
        payload = {
            "username": username,
            "full_name": full_name,
            "password": hashed_pw, # Ø³ÙŠØ®Ø²Ù† Ø§Ù„Ø±Ù…Ø² Ø§Ù„Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø´Ø±
            "role": role,
            "can_delete_entry": int(can_delete),
            "can_view_reports": int(can_reports),
            "can_edit_settings": int(can_settings),
            "can_manage_users": int(can_users)
        }
        
        response = supabase.table("users").insert(payload).execute()
        return True, "ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¬Ø§Ø­"
    except Exception as e:
        return False, str(e)

def delete_user(username):
    """Ø­Ø°Ù Ù…Ø³ØªØ®Ø¯Ù… Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        response = requests.delete(f"{URL}/users?username=eq.{username}", headers=HEADERS)
        if response.status_code in [200, 204]:
            return True, f"ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username} Ø¨Ù†Ø¬Ø§Ø­."
        return False, f"ÙØ´Ù„ Ø§Ù„Ø­Ø°ÙØŒ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±: {response.status_code}"
    except Exception as e:
        return False, str(e)

# --- 4. Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ---

def db_fetch(query, params=None):
    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø«Ø¨Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
    STD_COLUMNS = {
        "accounts": ["id", "acc_name", "name", "current_balance", "category", "opening_balance"],
        "journal": ["id", "date", "jv_date", "acc_name", "total_amount", "debit", "credit", "op_type", "description", "ref_no"]
    }
    
    table_name = "accounts"
    
    try:
        # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„
        clean_query = query.strip().upper()
        if "FROM " in clean_query:
            table_name = clean_query.split("FROM ")[1].split(" ")[0].lower().strip()
        else:
            table_name = query.strip().lower()

        # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        response = supabase.table(table_name).select("*").execute()
        df = pd.DataFrame(response.data) if response.data else pd.DataFrame()

        # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø­ØªÙ‰ ÙˆÙ‡ÙŠ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©)
        if not df.empty:
            # --- Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ§Ø±ÙŠØ® (ArrowTypeError) ---
            for col in df.columns:
                # ØªØ­ÙˆÙŠÙ„ Ø£ÙŠ Ø¹Ù…ÙˆØ¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ Ù†Øµ Ù„ÙŠØ¹Ø±Ø¶Ù‡ Streamlit Ø¨Ù„Ø§ Ù…Ø´Ø§ÙƒÙ„
                if 'date' in col.lower() or 'Ø§Ù„ØªØ§Ø±ÙŠØ®' in col or 'jv_date' in col:
                    df[col] = df[col].astype(str)
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ Ù…Ø¨Ø§Ù„Øº Ø§Ù„Ù…Ø¯ÙŠÙ† ÙˆØ§Ù„Ø¯Ø§Ø¦Ù† Ø¥Ù„Ù‰ Ø£ØµÙØ§Ø± Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† None
                if col in ['debit', 'credit', 'current_balance', 'total_amount', 'opening_balance']:
                    df[col] = df[col].fillna(0)

            # ØªÙˆØ­ÙŠØ¯ Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            if "acc_name" in df.columns and "name" not in df.columns:
                df["name"] = df["acc_name"]
            
            if table_name == "journal":
                if "date" in df.columns and "jv_date" not in df.columns:
                    df["jv_date"] = df["date"]
                elif "jv_date" in df.columns and "date" not in df.columns:
                    df["date"] = df["jv_date"]
        else:
            # 4. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙØ§Ø±ØºØ§Ù‹
            df = pd.DataFrame(columns=STD_COLUMNS.get(table_name, ["id"]))

        return df

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø­Ø±Ø¬ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {table_name}: {e}")
        return pd.DataFrame(columns=STD_COLUMNS.get(table_name, ["id"]))

def advanced_search_journal(query):
    try:
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ø³Ù… Ø§Ù„Ø­Ø³Ø§Ø¨ Ø£Ùˆ Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø£Ùˆ Ø§Ù„Ø¨ÙŠØ§Ù†
        res = supabase.table("journal").select("*").or_(f"acc_name.ilike.%{query}%,ref_no.ilike.%{query}%,description.ilike.%{query}%").order("id", desc=True).execute()
        return pd.DataFrame(res.data) if res.data else pd.DataFrame()
    except:
        return pd.DataFrame()

def generate_acc_code(category):
    prefix_map = {
        "Ù…ÙˆØ±Ø¯": "SUP", "Ø¹Ù…ÙŠÙ„": "CUS", "ØµÙ†Ø¯ÙˆÙ‚/ÙƒØ§Ø´": "CSH",
        "Ø¨Ù†Ùƒ": "BNK", "ÙØ±Ø¹": "BRN", "Ù…ØµØ±ÙˆÙØ§Øª": "EXP", "Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ø£Ø®Ø±Ù‰": "REV"
    }
    prefix = prefix_map.get(category, "ACC")
    year = 2026 # Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    
    try:
        # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ø­Ø³Ø§Ø¨ ØªÙ… ØªØ³Ø¬ÙŠÙ„Ù‡ ÙŠØ¨Ø¯Ø£ Ø¨Ù†ÙØ³ Ø§Ù„ÙƒÙˆØ¯
        res = supabase.table("accounts").select("acc_code").like("acc_code", f"{prefix}{year}-%").order("acc_code", desc=True).limit(1).execute()
        
        if res.data:
            last_code = res.data[0]['acc_code']
            # Ù†Ø£Ø®Ø° Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø£Ø®ÙŠØ± ÙˆÙ†Ø²ÙŠØ¯Ù‡ 1
            last_num = int(last_code.split('-')[-1])
            return f"{prefix}{year}-{str(last_num + 1).zfill(4)}"
        else:
            return f"{prefix}{year}-0001"
    except:
        return f"{prefix}{year}-0001"

def process_full_transaction(acc_name, offset_acc, op_type, amount, use_tax, description, ref_no, date_str, posted_by, due_date=None):
    """
    Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©: ØªØ¯Ø¹Ù… Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ­Ù‚Ø§Ù‚ Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¢Ø¬Ù„Ø©
    Ù„Ø¶Ù…Ø§Ù† Ø¸Ù‡ÙˆØ±Ù‡Ø§ ÙÙŠ ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø¯ÙŠÙˆÙ† ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª.
    """
    try:
        amount = float(amount)
        tax = (amount * 0.15) if use_tax else 0
        total = amount + tax
        
        # 1. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¯ÙŠÙ† ÙˆØ§Ù„Ø¯Ø§Ø¦Ù†
        is_revenue = any(x in op_type for x in ["Ø¨ÙŠØ¹", "Ù‚Ø¨Ø¶", "Ø¥ÙŠØ±Ø§Ø¯"])
        deb, crd = (0, total) if is_revenue else (total, 0)

        # 2. Ù…Ù†Ø·Ù‚ Ø°ÙƒÙŠ Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ­Ù‚Ø§Ù‚: 
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© "Ø¢Ø¬Ù„Ø©" ÙˆÙ„Ù… ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„ ØªØ§Ø±ÙŠØ® Ø§Ø³ØªØ­Ù‚Ø§Ù‚ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ø¶Ø§ÙØ© 30 ÙŠÙˆÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        final_due_date = due_date
        if "Ø¢Ø¬Ù„" in op_type and not due_date:
            from datetime import datetime, timedelta
            current_date = datetime.strptime(date_str, '%Y-%m-%d')
            final_due_date = (current_date + timedelta(days=30)).strftime('%Y-%m-%d')

        payload = {
            "date": date_str,
            "acc_name": acc_name,
            "offset_acc": offset_acc,
            "op_type": op_type,
            "description": description,
            "ref_no": ref_no,
            "base_amount": amount,
            "tax_amount": tax,
            "total_amount": total,
            "debit": deb,
            "credit": crd,
            "posted_by": posted_by,
            "due_date": final_due_date  # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        }
        
        res = supabase.table("journal").insert(payload).execute()
        
        if res.data:
            update_account_balance(acc_name, deb, crd)
            update_account_balance(offset_acc, crd, deb)
            return True, "âœ… ØªÙ… ØªØ±Ø­ÙŠÙ„ Ø§Ù„Ù‚ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­"
        
        return False, "âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
    except Exception as e:
        return False, f"âŒ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}"

def get_supplier_due_amounts():
    """Ø¬Ù„Ø¨ ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª Ø§Ù„Ø¢Ø¬Ù„Ø© Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    df = db_fetch("journal") 
    if df.empty or 'op_type' not in df.columns:
        return pd.DataFrame()

    # ØªØµÙÙŠØ© Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª Ø§Ù„Ø¢Ø¬Ù„Ø© ÙÙ‚Ø·
    due_df = df[df['op_type'].str.contains('Ø´Ø±Ø§Ø¡ Ø¢Ø¬Ù„', na=False)].copy()
    
    if due_df.empty:
        return pd.DataFrame()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¨Ø­Ø°Ø±
    due_df['jv_date'] = pd.to_datetime(due_df['jv_date']).dt.date
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ ØªØ§Ø±ÙŠØ® Ø§Ø³ØªØ­Ù‚Ø§Ù‚ØŒ Ù†ÙØªØ±Ø¶ 30 ÙŠÙˆÙ…Ø§Ù‹
    due_df['due_date'] = pd.to_datetime(due_df.get('due_date', None)).fillna(
        pd.to_datetime(due_df['jv_date']) + pd.Timedelta(days=30)
    ).dt.date
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
    today = datetime.now().date()
    due_df['days_left'] = due_df['due_date'].apply(lambda x: (x - today).days)
    
    return due_df[['acc_name', 'jv_date', 'due_date', 'total_amount', 'days_left']]
    
def log_event(user, action, details):
    try:
        payload = {
            "user_name": str(user),
            "action": str(action),
            "details": str(details) 
            # Ø­Ø°ÙÙ†Ø§ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ù€ timestamp Ù„Ù†ØªØ±Ùƒ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© ØªØ³Ø¬Ù„Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        }
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
        supabase.table("audit_log").insert(payload).execute()
    except Exception as e:
        # Ù‚Ù…Ù†Ø§ Ø¨ØªØºÙŠÙŠØ± Ø§Ù„Ø¨Ø±ÙŠÙ†Øª Ù„ÙŠØ¹Ø·ÙŠÙƒ Ø³Ø¨Ø¨ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø±Ø³Ø§Ù„Ø© Ø¹Ø§Ù…Ø©
        print(f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: ÙØ´Ù„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ audit_log. Ø§Ù„Ø³Ø¨Ø¨: {e}")

def update_account_balance(acc_name, debit_change=0, credit_change=0):
    """
    Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©: ØªØ¹ÙŠØ¯ Ø§Ø­ØªØ³Ø§Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ù…Ù† ÙˆØ§Ù‚Ø¹ Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù‚ÙŠØ¯ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø©
    ÙˆØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªØ±Ø§ÙƒÙ… Ø§Ù„ÙŠØ¯ÙˆÙŠ.
    """
    try:
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø§ÙØªØªØ§Ø­ÙŠ Ù…Ù† Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª
        acc_res = supabase.table("accounts").select("opening_balance").eq("acc_name", acc_name).execute()
        opening_bal = float(acc_res.data[0].get('opening_balance', 0)) if acc_res.data else 0.0
        
        # 2. Ø¬Ù„Ø¨ Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØ§Ù„Ø¯Ø§Ø¦Ù†Ø© Ù…Ù† Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù‚ÙŠÙˆØ¯ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø­Ø³Ø§Ø¨
        journal_res = supabase.table("journal").select("debit, credit").eq("acc_name", acc_name).execute()
        
        total_debit = sum(float(row.get('debit', 0)) for row in journal_res.data)
        total_credit = sum(float(row.get('credit', 0)) for row in journal_res.data)
        
        # 3. Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©
        # Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ = Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø§ÙØªØªØ§Ø­ÙŠ + (Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¯ÙŠÙ† - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¯Ø§Ø¦Ù†)
        new_balance = opening_bal + (total_debit - total_credit)
        
        # 4. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª
        supabase.table("accounts").update({"current_balance": new_balance}).eq("acc_name", acc_name).execute()
        
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨ {acc_name}: {e}")
        return False

def get_statement(acc_name, from_date, to_date):
    """
    Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©:
    1. ØªØ­Ø³Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„ (Ù‚Ø¨Ù„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©).
    2. ØªØ±ØªØ¨ Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø¨Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ù…Ø¹Ø±Ù ID Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ….
    """
    try:
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„ (Ù…Ø§ Ù‚Ø¨Ù„ ÙØªØ±Ø© Ø§Ù„Ø¨Ø­Ø«)
        # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ ÙÙŠ Ù…Ù„ÙÙƒ get_opening_balance_logic
        opening_bal = get_opening_balance_logic(acc_name, from_date)
        
        # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø±ÙƒØ§Øª Ù…Ù† Supabase Ù…Ø¹ ØªØ±ØªÙŠØ¨ Ù…Ø²Ø¯ÙˆØ¬ (Ø§Ù„ØªØ§Ø±ÙŠØ® Ø«Ù… ID)
        res = supabase.table("journal")\
            .select("*")\
            .eq("acc_name", acc_name)\
            .gte("date", from_date)\
            .lte("date", to_date)\
            .order("date", desc=False)\
            .order("id", desc=False)\
            .execute()
            
        df = pd.DataFrame(res.data) if res.data else pd.DataFrame()
        
        # 3. Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø·Ø± Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù„ÙŠØ¸Ù‡Ø± ÙÙŠ Ø£Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        opening_row = pd.DataFrame([{
            'date': pd.to_datetime(from_date),
            'ref_no': '---',
            'description': 'Ø±ØµÙŠØ¯ Ù…Ù†Ù‚ÙˆÙ„ Ù…Ù† ÙØªØ±Ø© Ø³Ø§Ø¨Ù‚Ø©',
            'debit': 0.0,
            'credit': 0.0,
            'balance': opening_bal
        }])

        if not df.empty:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ§Ù„ØªØ±ØªÙŠØ¨
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values(by=['date', 'id'], ascending=[True, True])
            
            # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠ Ø§Ù†Ø·Ù„Ø§Ù‚Ø§Ù‹ Ù…Ù† Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„
            # Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯ = Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„ + (Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ù…Ø¯ÙŠÙ† - Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø¯Ø§Ø¦Ù†)
            df['balance'] = opening_bal + (df['debit'] - df['credit']).cumsum()
            
            # Ø¯Ù…Ø¬ Ø³Ø·Ø± Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„ Ù…Ø¹ Ø¨Ù‚ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ§Øª
            df = pd.concat([opening_row, df], ignore_index=True)
        else:
            # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø­Ø±ÙƒØ§Øª ÙÙŠ Ø§Ù„ÙØªØ±Ø©ØŒ ÙŠØ¸Ù‡Ø± Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„ ÙÙ‚Ø·
            df = opening_row

        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ù„Ø¹Ø±Ø¶
        df['date_display'] = df['date'].dt.strftime('%Y-%m-%d')
        
        return df
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¯Ø§Ù„Ø© ÙƒØ´Ù Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø­Ø¯Ø«Ø©: {e}")
        return pd.DataFrame()

def init_db():
    """Ø¯Ø§Ù„Ø© Ù„ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØºÙŠØ± Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ Supabase)"""
    pass

def generate_jv_ref(op_type):
    prefix = "INV" if "Ø¨ÙŠØ¹" in op_type else "VCH"
    return f"{prefix}-{datetime.now().strftime('%y%m%d%H%M')}"

def get_recent_transactions(limit=20):
    try:
        res = requests.get(f"{URL}/journal?order=id.desc&limit={limit}", headers=HEADERS)
        return pd.DataFrame(res.json()) if res.status_code == 200 else pd.DataFrame()
    except:
        return pd.DataFrame()

def delete_journal_entry(entry_id, user_role, user_name):
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
    if user_role.lower() not in ["administrator", "admin"]:
        return False, "ğŸš« Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ØªÙ…Ù„Ùƒ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø­Ø°Ù"
        
    try:
        # Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°ÙØŒ ÙŠØ¬Ø¨ Ø¹ÙƒØ³ Ø£Ø«Ø± Ø§Ù„Ù‚ÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±ØµØ¯Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„ÙƒÙ†Ù‡ Ù…Ù…Ø§Ø±Ø³Ø© Ù…Ø­Ø§Ø³Ø¨ÙŠØ© Ø³Ù„ÙŠÙ…Ø©)
        res = supabase.table("journal").delete().eq("id", entry_id).execute()
        if res.data:
            log_event(user_name, "Ø­Ø°Ù Ù‚ÙŠØ¯", f"ØªÙ… Ø­Ø°Ù Ø§Ù„Ù‚ÙŠØ¯ Ø±Ù‚Ù… {entry_id}")
            return True, "âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ù‚ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­"
        return False, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠØ¯"
    except Exception as e:
        return False, str(e)

def db_write(table_name, data=None, action="INSERT", row_id=None):
    try:
        if action == "INSERT":
            res = supabase.table(table_name).insert(data).execute()
        elif action == "UPDATE":
            res = supabase.table(table_name).update(data).eq("id", row_id).execute()
        elif action == "DELETE":
            res = supabase.table(table_name).delete().eq("id", row_id).execute()
        return (True, "ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­") if res.data else (False, "ÙØ´Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
    except Exception as e:
        return False, str(e)

def update_account(acc_id, account_data):
    try:
        res = supabase.table("accounts").update(account_data).eq("id", acc_id).execute()
        return (True, "âœ… ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ«") if res.data else (False, "âŒ ÙØ´Ù„")
    except Exception as e:
        return False, str(e)
def update_record(table, column_name, value, update_data):
    """ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„Ø³Ø­Ø§Ø¨"""
    try:
        supabase.table(table).update(update_data).eq(column_name, value).execute()
        return True, "ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø¬Ø§Ø­ âœ…"
    except Exception as e:
        return False, f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {str(e)}"

    
def backup_system():
    try:
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù‚ÙŠÙˆØ¯
        df = db_fetch("journal") 
        if df.empty: return None
        
        # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ JSON Ù„Ø±ÙØ¹Ù‡Ø§ Ù„Ù„Ø³Ø­Ø§Ø¨
        json_data = df.to_json(orient='records')
        
        # 3. Ø§Ù„Ø±ÙØ¹ Ù„Ù„Ø³Ø­Ø§Ø¨
        entry = {
            "backup_date": datetime.now().strftime("%Y-%m-%d"),
            "data_json": json_data
        }
        supabase.table("system_backups").insert(entry).execute()
        
        # 4. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù CSV Ù…Ø­Ù„ÙŠ (Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙ†ØªØ¸Ø±Ù‡ ÙƒÙˆØ¯ Streamlit Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ)
        file_path = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        
        return file_path # Ø³ÙŠØ¹ÙˆØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù€ Streamlit Ù„ÙƒÙŠ ÙŠÙØªØ­Ù‡
    except Exception as e:
        print(f"Backup Error: {e}")
        return None

def get_backup_files():
    import glob
    return glob.glob("backup_*.csv")

def update_journal_entry(entry_id, new_acc, new_amt, new_desc, op_type):
    """ØªØ¹Ø¯ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚ÙŠØ¯ Ù…Ø§Ù„ÙŠ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹"""
    try:
        # 1. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        amount = float(new_amt)
        tax = amount * 0.15 
        total = amount + tax

        # 2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠ
        is_revenue = any(x in op_type for x in ["Ø¨ÙŠØ¹", "Ù‚Ø¨Ø¶", "Ø¥ÙŠØ±Ø§Ø¯"])
        deb, crd = (0, total) if is_revenue else (total, 0)

        # 3. Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…Ø­Ø¯Ø« (Payload)
        payload = {
            "acc_name": new_acc,
            "base_amount": amount,
            "tax_amount": tax,
            "total_amount": total,
            "description": new_desc, # ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„ ÙƒÙ…Ø§ Ø¸Ù‡Ø± ÙÙŠ Ø§Ù„ÙØ­Øµ
            "debit": deb,
            "credit": crd
        }
        
        # 4. Ø§Ù„ØªÙ†ÙÙŠØ° ÙÙŠ Supabase
        res = supabase.table("journal").update(payload).eq("id", entry_id).execute()
        
        if res.data:
            return True, "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­"
        return False, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"
    except Exception as e:
        return False, f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: {str(e)}"
    

def update_account(acc_id, account_data):
    """ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø§Ø¨ - Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø®Ø·Ø£ Ø§Ù„ØµÙˆØ±Ø© image_6eda80"""
    try:
        res = supabase.table("accounts").update(account_data).eq("id", acc_id).execute()
        return (True, "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø³Ø§Ø¨") if res.data else (False, "âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«")
    except Exception as e:
        return False, str(e)
    
def get_detailed_debts():
    """ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ø¯ÙŠÙˆÙ† Ø§Ù„Ù…Ø³ØªØ­Ù‚Ø© Ù„Ù„Ù…ÙˆØ±Ø¯ÙŠÙ†"""
    df = db_fetch("journal")
    if df.empty or 'op_type' not in df.columns:
        return pd.DataFrame(), pd.DataFrame()

    # 1. ØªØµÙÙŠØ© Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª Ø§Ù„Ø¢Ø¬Ù„Ø© ÙÙ‚Ø·
    due_df = df[df['op_type'].str.contains('Ø´Ø±Ø§Ø¡ Ø¢Ø¬Ù„', na=False)].copy()
    if due_df.empty:
        return pd.DataFrame(), pd.DataFrame()

    # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    today = datetime.now().date()
    due_df['due_date'] = pd.to_datetime(due_df.get('due_date', None)).fillna(
        pd.to_datetime(due_df['jv_date']) + pd.Timedelta(days=30)
    ).dt.date

    # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ£Ø®ÙŠØ± Ø¨Ø§Ù„Ø£ÙŠØ§Ù…
    due_df['days_diff'] = due_df['due_date'].apply(lambda x: (today - x).days)

    # Ø§Ù„ÙØ¦Ø© Ø£: Ù…Ø³ØªØ­Ù‚ÙˆÙ† Ø­Ø§Ù„ÙŠØ§Ù‹ (ØªØ§Ø±ÙŠØ® Ø§Ù„ÙŠÙˆÙ… ØªØ¬Ø§ÙˆØ² ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ­Ù‚Ø§Ù‚)
    urgent = due_df[due_df['days_diff'] >= 0].copy()
    
    # Ø§Ù„ÙØ¦Ø© Ø¨: Ø®Ø·Ø± Ø¬Ø¯Ø§Ù‹ (ØªØ¬Ø§ÙˆØ²ÙˆØ§ Ø´Ù‡Ø± ÙƒØ§Ù…Ù„ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø³ØªØ­Ù‚Ø§Ù‚)
    critical = urgent[urgent['days_diff'] > 30].copy()

    return urgent, critical

def create_pdf_report(df, account_name, start_date, end_date):
    """Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø©: ØªÙ…Ù†Ø¹ Ø®Ø±ÙˆØ¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØªØ±ØªØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯Ù‚Ø©"""
    try:
        buffer = io.BytesIO()
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ù…Ø¹ Ù‡ÙˆØ§Ù…Ø´ (Margins)
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=30, leftMargin=30, topMargin=30, bottomMargin=30)
        elements = []
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        pdfmetrics.registerFont(TTFont('ArabicFont', 'arial.ttf'))
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…Ø· Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø§Ù„ØªÙØ§Ù Ø§Ù„Ù†Øµ (Word Wrap)
        styles = getSampleStyleSheet()
        style_ar = styles['Normal']
        style_ar.fontName = 'ArabicFont'
        style_ar.fontSize = 10
        style_ar.alignment = 1  # Ø³Ù†ØªØ±
        style_ar.wordWrap = 'CJK' # ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø§Ù„ØªÙØ§Ù Ù„Ù…Ù†Ø¹ Ø®Ø±ÙˆØ¬ Ø§Ù„Ù†Øµ

        # 1. Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
        elements.append(Paragraph(f"<b>ØªÙ‚Ø±ÙŠØ± ÙƒØ´Ù Ø­Ø³Ø§Ø¨ ØªÙØµÙŠÙ„ÙŠ</b>", style_ar))
        elements.append(Paragraph(f"Ø§Ø³Ù… Ø§Ù„Ø­Ø³Ø§Ø¨: {account_name}", style_ar))
        elements.append(Paragraph(f"Ø§Ù„ÙØªØ±Ø© Ù…Ù† {start_date} Ø¥Ù„Ù‰ {end_date}", style_ar))
        elements.append(Spacer(1, 20)) # Ù…Ø³Ø§ÙØ© ÙØ§Ø±ØºØ©

        # 2. ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„
        # Ù†Ø¶Ø¹ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹
        table_data = [["Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù…Ø±Ø¬Ø¹", "Ø§Ù„Ø¨ÙŠØ§Ù†", "Ù…Ø¯ÙŠÙ†", "Ø¯Ø§Ø¦Ù†", "Ø§Ù„Ø±ØµÙŠØ¯"]]
        
        for _, row in df.iterrows():
            table_data.append([
                str(row['date'].date()) if hasattr(row['date'], 'date') else str(row['date']),
                str(row.get('ref_no', '')),
                Paragraph(str(row.get('description', '') or row.get('op_type', '')), style_ar), # Ù‡Ù†Ø§ Ø³Ø± Ø§Ù„Ø­Ù„
                f"{row.get('debit', 0):,.2f}",
                f"{row.get('credit', 0):,.2f}",
                f"{row.get('balance', 0):,.2f}"
            ])

        # 3. ØªØ­Ø¯ÙŠØ¯ Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ù…Ø¬Ù…ÙˆØ¹ Ø¹Ø±Ø¶ A4 Ø§Ù„Ù…ØªØ§Ø­ Ù‡Ùˆ 530 ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹)
        # ÙˆØ³Ø¹Ù†Ø§ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù† (180) Ù„ÙŠØ£Ø®Ø° Ø±Ø§Ø­ØªÙ‡ ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨Ø©
        column_widths = [75, 85, 180, 60, 60, 70]
        
        pdf_table = Table(table_data, colWidths=column_widths)

        # 4. ØªÙ†Ø³ÙŠÙ‚ Ø´ÙƒÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        style = TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#0D47A1")), # Ù„ÙˆÙ† Ø§Ù„ØªØ±ÙˆÙŠØ³Ø© Ø£Ø²Ø±Ù‚ ØºØ§Ù…Ù‚
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, -1), 'ArabicFont'),
            ('FONTSIZE', (0, 0), (-1, 0), 11),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 10),
            ('GRID', (0, 0), (-1, -1), 0.5, colors.black), # Ø±Ø³Ù… Ø®Ø·ÙˆØ· Ø§Ù„Ø´Ø¨ÙƒØ©
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'), # ØªÙˆØ³ÙŠØ· Ø§Ù„Ù†Øµ Ø¹Ù…ÙˆØ¯ÙŠØ§Ù‹
        ])
        pdf_table.setStyle(style)

        elements.append(pdf_table)

        # 5. Ø§Ù„ØªØ°ÙŠÙŠÙ„ (Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ)
        final_bal = df['balance'].iloc[-1] if not df.empty else 0
        elements.append(Spacer(1, 20))
        elements.append(Paragraph(f"Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø³ØªØ­Ù‚: {abs(final_bal):,.2f} Ø±ÙŠØ§Ù„", style_ar))
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ PDF
        doc.build(elements)
        buffer.seek(0)
        return buffer.getvalue()
        
    except Exception as e:
        print(f"PDF Error: {str(e)}")
        return None

def get_opening_balance_logic(acc_name, start_date):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ³Ø¨Ù‚ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø®ØªØ§Ø±"""
    try:
        # Ø¬Ù„Ø¨ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø¹Ù†Ø¯ Ø§Ù„ØªØ£Ø³ÙŠØ³
        acc_data = supabase.table("accounts").select("opening_balance").eq("acc_name", acc_name).execute()
        initial_bal = float(acc_data.data[0]['opening_balance']) if acc_data.data else 0.0
        
        # Ø¬Ù„Ø¨ ÙƒØ§ÙØ© Ø§Ù„Ø­Ø±ÙƒØ§Øª Ù‚Ø¨Ù„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        pre_entries = supabase.table("journal").select("debit, credit").eq("acc_name", acc_name).lt("date", start_date).execute()
        
        if pre_entries.data:
            sum_debit = sum(float(item['debit']) for item in pre_entries.data)
            sum_credit = sum(float(item['credit']) for item in pre_entries.data)
            return initial_bal + (sum_debit - sum_credit)
        
        return initial_bal
    except:
        return 0.0
    
def restore_backup_to_supabase(uploaded_file):
    """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù‚ÙŠÙˆØ¯ Ù…Ù† Ù…Ù„Ù CSV Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø­Ø§Ø¨"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = pd.read_csv(uploaded_file)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© (Ø­Ø°Ù id Ù„ÙŠØªÙˆÙ„Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
        if 'id' in df.columns:
            df = df.drop(columns=['id'])
            
        data_to_restore = df.to_dict(orient='records')
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³Ø­Ø§Ø¨
        res = supabase.table("journal").insert(data_to_restore).execute()
        
        return True, f"âœ… ØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ {len(res.data)} Ù‚ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­"
    except Exception as e:
        return False, f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹: {str(e)}"
    
def recalculate_all_balances():
    try:
        # Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª
        acc_res = supabase.table("accounts").select("acc_name").execute()
        if not acc_res.data: return False, "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø³Ø§Ø¨Ø§Øª"
        
        for acc in acc_res.data:
            name = acc['acc_name']
            # Ø¬Ù„Ø¨ Ø­Ø±ÙƒØ§Øª Ù‡Ø°Ø§ Ø§Ù„Ø­Ø³Ø§Ø¨
            j_res = supabase.table("journal").select("debit, credit").eq("acc_name", name).execute()
            
            total_debit = sum(float(row.get('debit', 0)) for row in j_res.data)
            total_credit = sum(float(row.get('credit', 0)) for row in j_res.data)
            new_bal = total_debit - total_credit
            
            # Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª (ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù…Ù‡ current_balance)
            supabase.table("accounts").update({"current_balance": new_bal}).eq("acc_name", name).execute()
            
        return True, "ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø¬Ø§Ø­"
    except Exception as e:
        print(f"Error in recalculate: {e}")
        return False, str(e)

def auto_smart_backup():
    """
    Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ: 
    1. ÙŠØ­ÙØ¸ Ù†Ø³Ø®Ø© CSV Ù…Ø­Ù„ÙŠØ§Ù‹.
    2. ÙŠØ­ÙØ¸ Ù†Ø³Ø®Ø© JSON ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨.
    3. ÙŠØ­Ø¯Ù‘Ø« Ù†Ø³Ø®Ø© Ø§Ù„ÙŠÙˆÙ… Ø¥Ø°Ø§ ØªÙƒØ±Ø±ØªØŒ ÙˆÙŠØ­ØªÙØ¸ Ø¨Ù†Ø³Ø® Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.
    """
    try:
        # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        res = supabase.table("journal").select("*").execute()
        current_data = res.data
        today_date = datetime.now().strftime('%Y-%m-%d')
        
        # --- Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ© (JSON) ---
        # ÙØ­Øµ Ù‡Ù„ ØªÙˆØ¬Ø¯ Ù†Ø³Ø®Ø© Ù„Ù„ÙŠÙˆÙ…ØŸ
        existing = supabase.table("system_backups").select("id").eq("backup_date", today_date).execute()
        
        payload = {
            "backup_date": today_date,
            "data_json": current_data
        }
        
        if existing.data:
            # ØªØ­Ø¯ÙŠØ« Ù†Ø³Ø®Ø© Ø§Ù„ÙŠÙˆÙ… (Ù„ØªØ¨Ù‚Ù‰ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¹Ù†Ø¯ Ø¢Ø®Ø± Ø¯Ù‚ÙŠÙ‚Ø©)
            supabase.table("system_backups").update(payload).eq("id", existing.data[0]['id']).execute()
        else:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„ÙŠÙˆÙ… Ø¬Ø¯ÙŠØ¯
            supabase.table("system_backups").insert(payload).execute()
            
        # --- Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© (CSV) ---
        df = pd.DataFrame(current_data)
        filename = f"backup_{today_date}.csv"
        df.to_csv(filename, index=False)
        
        return True
    except Exception as e:
        print(f"Smart Backup Error: {e}")
        return False

def get_cloud_backups():
    try:
        # Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø°ÙŠ Ø£ØµÙ„Ø­Ù†Ø§Ù‡
        response = supabase.table('system_backups').select('*').execute()
        return response.data if response.data else []
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return []

def restore_from_smart_backup(backup_id):
    """Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­ØµÙ†Ø©: Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¶Ù…Ø§Ù† ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù‡ÙŠÙƒÙ„Ø©"""
    try:
        # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ø±Ù
        if not backup_id or str(backup_id) in ["0", "None"]:
            return False, "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹"

        # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨
        res = supabase.table("system_backups").select("data_json").eq("id", int(backup_id)).execute()
        if not res.data: 
            return False, "âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨"
        
        raw_data = res.data[0]['data_json']
        records = json.loads(raw_data) if isinstance(raw_data, str) else raw_data

        if not records:
            return False, "âš ï¸ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ Ø³Ø¬Ù„Ø§Øª"

        # 3. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªÙŠ ØªÙˆÙ„Ø¯Ù‡Ø§ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
        # Ù‡Ø°Ø§ ÙŠÙ…Ù†Ø¹ ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª (Primary Key Conflicts)
        clean_records = []
        for r in records:
            # Ù†Ø­ØªÙØ¸ Ø¨ÙƒÙ„ Ø´ÙŠØ¡ Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
            item = {k: v for k, v in r.items() if k not in ['id', 'created_at']}
            clean_records.append(item)

        # 4. Ø§Ù„Ø­Ø°Ù Ø§Ù„Ø¢Ù…Ù† (Force Clear) 
        # Ù†Ø³ØªØ®Ø¯Ù… gte(id, 0) Ù„Ø£Ù†Ù‡Ø§ Ø£Ø³Ø±Ø¹ ÙˆØ£Ø¶Ù…Ù† ÙÙŠ Ø§Ù„ÙÙ„ØªØ±Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        try:
            supabase.table("journal").delete().gte("id", 0).execute()
        except:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø¹Ø±Ù Ù„ÙŠØ³ Ø±Ù‚Ù…Ø§Ù‹ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ù†ØµÙŠ ÙƒØ¨Ø¯ÙŠÙ„
            supabase.table("journal").delete().neq("acc_name", "NULL_DATA_RESERVED").execute()
        
        # 5. Ø§Ù„Ø±ÙØ¹ Ø§Ù„Ø°ÙƒÙŠ Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (Batching)
        # ØªÙ… ØªØµØºÙŠØ± Ø§Ù„Ø¯ÙØ¹Ø© Ù„Ù€ 100 Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² Ø­Ø¬Ù… Ø§Ù„Ø·Ù„Ø¨ (Request Size Limit)
        chunk_size = 100
        for i in range(0, len(clean_records), chunk_size):
            batch = clean_records[i:i + chunk_size]
            supabase.table("journal").insert(batch).execute()
            
        # 6. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø±ØµØ¯Ø© ÙÙˆØ±Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù„Ø¶Ù…Ø§Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        recalculate_all_balances() 
        
        return True, f"âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© {len(clean_records)} Ù‚ÙŠØ¯ Ù…Ø§Ù„ÙŠ ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø±ØµØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­"

    except Exception as e:
        error_msg = str(e)
        if "UUID" in error_msg:
            return False, "âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª: ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"

        return False, f"âŒ ÙØ´Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {error_msg}"

